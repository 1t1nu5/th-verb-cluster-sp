from google.colab import drive
drive.mount("/content/drive")

!pip -q install -U huggingface_hub datasets

from huggingface_hub import snapshot_download
from pathlib import Path

SAVE_DIR = Path("/content/drive/MyDrive/Colab_Datasets/VV/thaisum_parquet")

snapshot_download(
    repo_id="pythainlp/thaisum",
    repo_type="dataset",
    local_dir=str(SAVE_DIR),
    local_dir_use_symlinks=False,
    allow_patterns=["data/*.parquet"]
)

print("Saved to:", SAVE_DIR)
print("Parquet files found:", len(list((SAVE_DIR / "data").glob("*.parquet"))))

!pip -q install datasets pyahocorasick tqdm pandas numpy

from google.colab import drive
drive.mount("/content/drive")

from datasets import load_dataset
from pathlib import Path
import re
import numpy as np
import pandas as pd
from tqdm.auto import tqdm
import ahocorasick
from collections import defaultdict

SAVE_DIR = Path("/content/drive/MyDrive/Colab_Datasets/VV/thaisum_parquet")
DATA_DIR = SAVE_DIR / "data"

OUT_DIR = Path("/content/drive/MyDrive/Colab_Datasets/VV")
OUT_DIR.mkdir(parents=True, exist_ok=True)

VERB_CSV_PATH = Path("/content/drive/MyDrive/Colab_Datasets/VV/Wiktionary_Thai_verb_26122025.csv")
NOUN_CSV_PATH = Path("/content/drive/MyDrive/Colab_Datasets/VV/Wiktionary_Thai_noun_27122025.csv")

ADVERB_CSV_PATH    = Path("/content/drive/MyDrive/Colab_Datasets/VV/Wiktionary_Thai_adverb_02012026.csv")
ADJECTIVE_CSV_PATH = Path("/content/drive/MyDrive/Colab_Datasets/VV/Wiktionary_Thai_adjective_02012026.csv")
PRONOUN_CSV_PATH   = Path("/content/drive/MyDrive/Colab_Datasets/VV/Wiktionary_Thai_pronoun_02012026.csv")

SPLIT = "train"
TEXT_FIELD = "body"
MAX_ROWS = -1
CHUNK_WRITE = 200_000
SKIP_IF_OUTPUT_EXISTS = True

ENABLE = {
    "verb-verb": True,
    "noun-verb": True,
    "verb-noun": True,
    "verb-(noun)-verb": True,
    "verb-(verb)-verb": True,
    "adverb-verb": True,
    "verb-adverb": True,
    "verb-(adverb)-verb": True,
    "adjective-verb": True,
    "verb-adjective": True,
    "verb-(adjective)-verb": True,
    "pronoun-verb": True,
    "verb-pronoun": True,
    "verb-(pronoun)-verb": True,
}

ALLOW_OVERLAP_MIDDLE = {
    "noun": True,
    "adverb": True,
    "adjective": True,
    "pronoun": True,
}

OUT = {
    "verb-verb": OUT_DIR / "Thaisum_verb-verb_pairs.csv",

    "noun-verb": OUT_DIR / "Thaisum_noun-verb_pairs.csv",
    "verb-noun": OUT_DIR / "Thaisum_verb-noun_pairs.csv",
    "verb-(noun)-verb": OUT_DIR / "Thaisum_verb-(noun)-verb_pairs.csv",

    "verb-(verb)-verb": OUT_DIR / "Thaisum_verb-(verb)-verb_pairs.csv",

    "adverb-verb": OUT_DIR / "Thaisum_adverb-verb_pairs.csv",
    "verb-adverb": OUT_DIR / "Thaisum_verb-adverb_pairs.csv",
    "verb-(adverb)-verb": OUT_DIR / "Thaisum_verb-(adverb)-verb_pairs.csv",

    "adjective-verb": OUT_DIR / "Thaisum_adjective-verb_pairs.csv",
    "verb-adjective": OUT_DIR / "Thaisum_verb-adjective_pairs.csv",
    "verb-(adjective)-verb": OUT_DIR / "Thaisum_verb-(adjective)-verb_pairs.csv",

    "pronoun-verb": OUT_DIR / "Thaisum_pronoun-verb_pairs.csv",
    "verb-pronoun": OUT_DIR / "Thaisum_verb-pronoun_pairs.csv",
    "verb-(pronoun)-verb": OUT_DIR / "Thaisum_verb-(pronoun)-verb_pairs.csv",
}

if SKIP_IF_OUTPUT_EXISTS:
    for k, path in OUT.items():
        if ENABLE.get(k, False) and path.exists():
            print(f"[SKIP] {k} enabled but output exists: {path}")
            ENABLE[k] = False

print("\nEnabled jobs:")
for k, v in ENABLE.items():
    if v:
        print("  ✅", k)

THAI_RE = re.compile(r"^[\u0E00-\u0E7F ]+$")

def load_wordlist_onecol(csv_path: Path, label: str):
    wdf = pd.read_csv(csv_path, header=None, names=[label], encoding="utf-8-sig")
    series = (
        wdf[label]
        .astype(str)
        .str.replace("\ufeff", "", regex=False)
        .str.strip()
        .replace({"": np.nan, "nan": np.nan, "None": np.nan})
        .dropna()
    )
    words = [w for w in series.unique().tolist() if THAI_RE.match(w)]
    if not words:
        raise ValueError(f"No usable Thai {label}s found in {csv_path}")
    return words

def build_automaton(words):
    A = ahocorasick.Automaton()
    for i, w in enumerate(words):
        A.add_word(w, i)
    A.make_automaton()
    lens = np.array([len(w) for w in words], dtype=np.int32)
    return A, lens

data_files = {
    "train": sorted(str(p) for p in DATA_DIR.glob("train-*.parquet")),
    "validation": sorted(str(p) for p in DATA_DIR.glob("validation-*.parquet")),
    "test": sorted(str(p) for p in DATA_DIR.glob("test-*.parquet")),
}
if not data_files["train"]:
    raise FileNotFoundError(f"No train parquet files found in: {DATA_DIR}")

ds = load_dataset("parquet", data_files=data_files)
print(ds)

VERBS = load_wordlist_onecol(VERB_CSV_PATH, "verb")
V = len(VERBS)
verb_set = set(VERBS)
print("Loaded verbs:", V)

need_nouns = any(ENABLE.get(k, False) for k in ["noun-verb", "verb-noun", "verb-(noun)-verb"])
if need_nouns:
    NOUNS = load_wordlist_onecol(NOUN_CSV_PATH, "noun")
    N = len(NOUNS)
    noun_set = set(NOUNS)
    OVERLAP_NOUN_VERB = verb_set.intersection(noun_set)
    noun_in_overlap = np.array([w in OVERLAP_NOUN_VERB for w in NOUNS], dtype=bool)
    print("Loaded nouns:", N, " overlap(noun∩verb):", len(OVERLAP_NOUN_VERB))
else:
    NOUNS = None
    N = 0
    noun_in_overlap = None

POS_LISTS = {}
for pos, path in [("adverb", ADVERB_CSV_PATH), ("adjective", ADJECTIVE_CSV_PATH), ("pronoun", PRONOUN_CSV_PATH)]:
    need_pos = any(ENABLE.get(k, False) for k in [f"{pos}-verb", f"verb-{pos}", f"verb-({pos})-verb"])
    if need_pos:
        words = load_wordlist_onecol(path, pos)
        overlap = verb_set.intersection(set(words))
        POS_LISTS[pos] = {
            "words": words,
            "X": len(words),
            "overlap_set": overlap,
            "x_in_overlap": np.array([w in overlap for w in words], dtype=bool)
        }
        print(f"Loaded {pos}s:", len(words), f" overlap({pos}∩verb):", len(overlap))

A_verb, lens_verb = build_automaton(VERBS)

if need_nouns:
    A_noun, lens_noun = build_automaton(NOUNS)

for pos, spec in POS_LISTS.items():
    A_x, lens_x = build_automaton(spec["words"])
    spec["A"] = A_x
    spec["lens"] = lens_x

verbs_arr = np.array(VERBS, dtype=object)

if ENABLE.get("verb-verb", False):
    TOTAL_VV = V * V
    occ_vv = np.zeros(TOTAL_VV, dtype=np.int64)
    txt_vv = np.zeros(TOTAL_VV, dtype=np.int32)

if ENABLE.get("noun-verb", False):
    TOTAL_NV = N * V
    occ_nv = np.zeros(TOTAL_NV, dtype=np.int64)
    txt_nv = np.zeros(TOTAL_NV, dtype=np.int32)

if ENABLE.get("verb-noun", False):
    TOTAL_VN = V * N
    occ_vn = np.zeros(TOTAL_VN, dtype=np.int64)
    txt_vn = np.zeros(TOTAL_VN, dtype=np.int32)

if ENABLE.get("verb-(noun)-verb", False):
    TOTAL_VV = V * V
    occ_vnv = np.zeros(TOTAL_VV, dtype=np.int64)
    txt_vnv = np.zeros(TOTAL_VV, dtype=np.int32)

if ENABLE.get("verb-(verb)-verb", False):
    TOTAL_VV = V * V
    occ_vvv = np.zeros(TOTAL_VV, dtype=np.int64)
    txt_vvv = np.zeros(TOTAL_VV, dtype=np.int32)

for pos, spec in POS_LISTS.items():
    X = spec["X"]
    if ENABLE.get(f"{pos}-verb", False):
        spec["occ_xv"] = np.zeros(X * V, dtype=np.int64)
        spec["txt_xv"] = np.zeros(X * V, dtype=np.int32)
    if ENABLE.get(f"verb-{pos}", False):
        spec["occ_vx"] = np.zeros(V * X, dtype=np.int64)
        spec["txt_vx"] = np.zeros(V * X, dtype=np.int32)
    if ENABLE.get(f"verb-({pos})-verb", False):
        spec["occ_vxv"] = np.zeros(V * V, dtype=np.int64)
        spec["txt_vxv"] = np.zeros(V * V, dtype=np.int32)

any_enabled = any(ENABLE.values())
if not any_enabled:
    print("\nNothing enabled. Exiting without scanning.")
    raise SystemExit

data = ds[SPLIT]
if MAX_ROWS is None or MAX_ROWS == -1:
    iterable = data
    total_for_tqdm = len(data)
else:
    n_rows = min(int(MAX_ROWS), len(data))
    iterable = data.select(range(n_rows))
    total_for_tqdm = n_rows

for row in tqdm(iterable, total=total_for_tqdm, desc=f"Scanning {SPLIT}"):
    text = row.get(TEXT_FIELD, "") or ""

    v_starts = defaultdict(list)
    v_ends   = defaultdict(list)
    v_starts_with_end = defaultdict(list)
    for end_pos, vid in A_verb.iter(text):
        start_pos = end_pos - lens_verb[vid] + 1
        v_starts[start_pos].append(vid)
        v_ends[end_pos].append(vid)
        v_starts_with_end[start_pos].append((vid, end_pos))

    if need_nouns:
        n_starts = defaultdict(list)
        n_ends   = defaultdict(list)
        n_starts_with_end = defaultdict(list)
        for end_pos, nid in A_noun.iter(text):
            start_pos = end_pos - lens_noun[nid] + 1
            n_starts[start_pos].append(nid)
            n_ends[end_pos].append(nid)
            n_starts_with_end[start_pos].append((nid, end_pos))

    if ENABLE.get("verb-verb", False):
        seen = set()
        for e, left_vs in v_ends.items():
            right_vs = v_starts.get(e + 1)
            if not right_vs:
                continue
            for v1 in left_vs:
                base = v1 * V
                for v2 in right_vs:
                    code = base + v2
                    occ_vv[code] += 1
                    seen.add(code)
        for code in seen:
            txt_vv[code] += 1

    if ENABLE.get("verb-(verb)-verb", False):
        seen = set()
        for e, left_vs in v_ends.items():
            mids = v_starts_with_end.get(e + 1)
            if not mids:
                continue
            for v1 in left_vs:
                base = v1 * V
                for (vmid, mid_end) in mids:
                    right_vs = v_starts.get(mid_end + 1)
                    if not right_vs:
                        continue
                    for v2 in right_vs:
                        code = base + v2
                        occ_vvv[code] += 1
                        seen.add(code)
        for code in seen:
            txt_vvv[code] += 1

    if ENABLE.get("noun-verb", False):
        seen = set()
        for e, left_ns in n_ends.items():
            right_vs = v_starts.get(e + 1)
            if not right_vs:
                continue
            for nid in left_ns:
                if noun_in_overlap[nid]:
                    continue
                base = nid * V
                for vid in right_vs:
                    code = base + vid
                    occ_nv[code] += 1
                    seen.add(code)
        for code in seen:
            txt_nv[code] += 1

    if ENABLE.get("verb-noun", False):
        seen = set()
        for e, left_vs in v_ends.items():
            right_ns = n_starts.get(e + 1)
            if not right_ns:
                continue
            for vid in left_vs:
                base = vid * N
                for nid in right_ns:
                    if noun_in_overlap[nid]:
                        continue
                    code = base + nid
                    occ_vn[code] += 1
                    seen.add(code)
        for code in seen:
            txt_vn[code] += 1

    if ENABLE.get("verb-(noun)-verb", False):
        allow_mid = ALLOW_OVERLAP_MIDDLE.get("noun", True)
        seen = set()
        for e, left_vs in v_ends.items():
            mids = n_starts_with_end.get(e + 1)
            if not mids:
                continue
            for v1 in left_vs:
                base = v1 * V
                for (nid, n_end) in mids:
                    if (not allow_mid) and noun_in_overlap[nid]:
                        continue
                    right_vs = v_starts.get(n_end + 1)
                    if not right_vs:
                        continue
                    for v2 in right_vs:
                        code = base + v2
                        occ_vnv[code] += 1
                        seen.add(code)
        for code in seen:
            txt_vnv[code] += 1

    for pos, spec in POS_LISTS.items():
        A_x = spec["A"]
        lens_x = spec["lens"]
        X = spec["X"]
        x_in_overlap = spec["x_in_overlap"]
        allow_mid = ALLOW_OVERLAP_MIDDLE.get(pos, True)

        x_starts = defaultdict(list)
        x_ends   = defaultdict(list)
        x_starts_with_end = defaultdict(list)
        for end_pos, xid in A_x.iter(text):
            start_pos = end_pos - lens_x[xid] + 1
            x_starts[start_pos].append(xid)
            x_ends[end_pos].append(xid)
            x_starts_with_end[start_pos].append((xid, end_pos))

        if ENABLE.get(f"{pos}-verb", False):
            seen = set()
            for e, left_xs in x_ends.items():
                right_vs = v_starts.get(e + 1)
                if not right_vs:
                    continue
                for xid in left_xs:
                    if x_in_overlap[xid]:
                        continue
                    base = xid * V
                    for vid in right_vs:
                        code = base + vid
                        spec["occ_xv"][code] += 1
                        seen.add(code)
            for code in seen:
                spec["txt_xv"][code] += 1

        if ENABLE.get(f"verb-{pos}", False):
            seen = set()
            for e, left_vs in v_ends.items():
                right_xs = x_starts.get(e + 1)
                if not right_xs:
                    continue
                for vid in left_vs:
                    base = vid * X
                    for xid in right_xs:
                        if x_in_overlap[xid]:
                            continue
                        code = base + xid
                        spec["occ_vx"][code] += 1
                        seen.add(code)
            for code in seen:
                spec["txt_vx"][code] += 1

        if ENABLE.get(f"verb-({pos})-verb", False):
            seen = set()
            for e, left_vs in v_ends.items():
                mids = x_starts_with_end.get(e + 1)
                if not mids:
                    continue
                for v1 in left_vs:
                    base = v1 * V
                    for (xid, x_end) in mids:
                        if (not allow_mid) and x_in_overlap[xid]:
                            continue
                        right_vs = v_starts.get(x_end + 1)
                        if not right_vs:
                            continue
                        for v2 in right_vs:
                            code = base + v2
                            spec["occ_vxv"][code] += 1
                            seen.add(code)
            for code in seen:
                spec["txt_vxv"][code] += 1

print("Done counting.")

def write_adj_left_right(left_words, right_words, occ, txt, out_path, left_name, right_name,
                         skip_left_mask=None, total_chunk=CHUNK_WRITE):
    L = len(left_words)
    R = len(right_words)
    left_arr = np.array(left_words, dtype=object)
    right_arr = np.array(right_words, dtype=object)
    TOTAL = L * R

    wrote_header = False
    for start in tqdm(range(0, TOTAL, total_chunk), desc=f"Writing {left_name}-{right_name} CSV"):
        end = min(start + total_chunk, TOTAL)
        idx = np.arange(start, end, dtype=np.int64)
        l_ids = (idx // R).astype(np.int64)
        r_ids = (idx %  R).astype(np.int64)

        keep = np.ones_like(l_ids, dtype=bool)
        if skip_left_mask is not None:
            keep = ~skip_left_mask[l_ids]
        if not np.any(keep):
            continue

        l_ids_k = l_ids[keep]
        r_ids_k = r_ids[keep]
        codes   = (l_ids_k * R + r_ids_k).astype(np.int64)

        left_col = left_arr[l_ids_k]
        right_col = right_arr[r_ids_k]

        df = pd.DataFrame({
            left_name: left_col,
            right_name: right_col,
            "needle": (left_col + right_col),
            "total_occurrences": occ[codes],
            "texts_with_match": txt[codes],
        })

        df.to_csv(
            out_path,
            mode="w" if not wrote_header else "a",
            header=(not wrote_header),
            index=False,
            encoding="utf-8-sig"
        )
        wrote_header = True

    print("Saved:", out_path)

def write_vv_like(occ, txt, out_path, marker):
    TOTAL = V * V
    for start in tqdm(range(0, TOTAL, CHUNK_WRITE), desc=f"Writing {out_path.name}"):
        end = min(start + CHUNK_WRITE, TOTAL)
        idx = np.arange(start, end, dtype=np.int64)
        p_ids = (idx // V).astype(np.int64)
        s_ids = (idx %  V).astype(np.int64)

        pref = verbs_arr[p_ids]
        suff = verbs_arr[s_ids]

        df = pd.DataFrame({
            "prefix": pref,
            "suffix": suff,
            "needle": (pref + marker + suff),
            "total_occurrences": occ[start:end],
            "texts_with_match": txt[start:end],
        })

        df.to_csv(
            out_path,
            mode="w" if start == 0 else "a",
            header=(start == 0),
            index=False,
            encoding="utf-8-sig"
        )
    print("Saved:", out_path)

if ENABLE.get("verb-verb", False):
    write_vv_like(occ_vv, txt_vv, OUT["verb-verb"], marker="")

if ENABLE.get("verb-(verb)-verb", False):
    write_vv_like(occ_vvv, txt_vvv, OUT["verb-(verb)-verb"], marker="<V>")

if ENABLE.get("noun-verb", False):
    write_adj_left_right(
        left_words=NOUNS, right_words=VERBS,
        occ=occ_nv, txt=txt_nv,
        out_path=OUT["noun-verb"],
        left_name="noun", right_name="verb",
        skip_left_mask=noun_in_overlap
    )

if ENABLE.get("verb-noun", False):
    out_path = OUT["verb-noun"]
    wrote_header = False
    for start in tqdm(range(0, V * N, CHUNK_WRITE), desc="Writing verb-noun CSV"):
        end = min(start + CHUNK_WRITE, V * N)
        idx = np.arange(start, end, dtype=np.int64)

        v_ids = (idx // N).astype(np.int64)
        n_ids = (idx %  N).astype(np.int64)

        keep = ~noun_in_overlap[n_ids]
        if not np.any(keep):
            continue

        v_ids_k = v_ids[keep]
        n_ids_k = n_ids[keep]
        codes   = (v_ids_k * N + n_ids_k).astype(np.int64)

        verb_col = verbs_arr[v_ids_k]
        noun_col = np.array(NOUNS, dtype=object)[n_ids_k]

        df = pd.DataFrame({
            "verb": verb_col,
            "noun": noun_col,
            "needle": (verb_col + noun_col),
            "total_occurrences": occ_vn[codes],
            "texts_with_match": txt_vn[codes],
        })

        df.to_csv(
            out_path,
            mode="w" if not wrote_header else "a",
            header=(not wrote_header),
            index=False,
            encoding="utf-8-sig"
        )
        wrote_header = True
    print("Saved:", out_path)

if ENABLE.get("verb-(noun)-verb", False):
    write_vv_like(occ_vnv, txt_vnv, OUT["verb-(noun)-verb"], marker="<N>")

for pos, spec in POS_LISTS.items():
    if ENABLE.get(f"{pos}-verb", False):
        write_adj_left_right(
            left_words=spec["words"], right_words=VERBS,
            occ=spec["occ_xv"], txt=spec["txt_xv"],
            out_path=OUT[f"{pos}-verb"],
            left_name=pos, right_name="verb",
            skip_left_mask=spec["x_in_overlap"]
        )

    if ENABLE.get(f"verb-{pos}", False):
        out_path = OUT[f"verb-{pos}"]
        X = spec["X"]
        x_in_overlap = spec["x_in_overlap"]
        pos_arr = np.array(spec["words"], dtype=object)

        wrote_header = False
        for start in tqdm(range(0, V * X, CHUNK_WRITE), desc=f"Writing verb-{pos} CSV"):
            end = min(start + CHUNK_WRITE, V * X)
            idx = np.arange(start, end, dtype=np.int64)

            v_ids = (idx // X).astype(np.int64)
            x_ids = (idx %  X).astype(np.int64)

            keep = ~x_in_overlap[x_ids]
            if not np.any(keep):
                continue

            v_ids_k = v_ids[keep]
            x_ids_k = x_ids[keep]
            codes   = (v_ids_k * X + x_ids_k).astype(np.int64)

            verb_col = verbs_arr[v_ids_k]
            pos_col  = pos_arr[x_ids_k]

            df = pd.DataFrame({
                "verb": verb_col,
                pos: pos_col,
                "needle": (verb_col + pos_col),
                "total_occurrences": spec["occ_vx"][codes],
                "texts_with_match": spec["txt_vx"][codes],
            })

            df.to_csv(
                out_path,
                mode="w" if not wrote_header else "a",
                header=(not wrote_header),
                index=False,
                encoding="utf-8-sig"
            )
            wrote_header = True
        print("Saved:", out_path)

    if ENABLE.get(f"verb-({pos})-verb", False):
        marker = f"<{pos[:1].upper()}>"
        write_vv_like(spec["occ_vxv"], spec["txt_vxv"], OUT[f"verb-({pos})-verb"], marker=marker)

print("\nALL DONE ✅")
